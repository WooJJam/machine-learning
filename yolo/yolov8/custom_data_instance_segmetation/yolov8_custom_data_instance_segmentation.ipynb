{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ../train/images\n",
      "val: ../valid/images\n",
      "test: ../test/images\n",
      "\n",
      "nc: 1\n",
      "names: ['face']\n",
      "\n",
      "roboflow:\n",
      "  workspace: mohamed-traore-2ekkp\n",
      "  project: face-detection-mik1i\n",
      "  version: 24\n",
      "  license: CC BY 4.0\n",
      "  url: https://universe.roboflow.com/mohamed-traore-2ekkp/face-detection-mik1i/dataset/24"
     ]
    }
   ],
   "source": [
    "!cat /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ïª§Ïä§ÌÖÄ Îç∞Ïù¥ÌÑ∞ ÎßûÎäî YAML ÌååÏùº ÎßåÎì§Í∏∞\n",
    "\n",
    "#### YOLOv* ÌïôÏäµÍ≥º Í≤ÄÏ¶ùÏóê ÌïÑÏöîÌïú train, valid Îç∞Ïù¥ÌÑ∞Ïùò ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÏôÄ Segmentation ÌïòÍ≥† Ïã∂ÏùÄ ÌÅ¥ÎûòÏä§ Í∞úÏàò Í∑∏Î¶¨Í≥† Ìï¥Îãπ ÌÅ¥ÎûòÏä§Ïùò (Î¨∏ÏûêÏó¥) Ïù¥Î¶ÑÏù¥ Ï†ÄÏû•ÎêòÏñ¥ ÏûàÎäî YAML ÌååÏùºÏùÑ Î∞òÎìúÏãú ÎßåÎì§Ïñ¥ÏïÑÌñ†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML in /Users/woojjam/anaconda3/lib/python3.11/site-packages (6.0)\n",
      "Requirement already satisfied: ultralytics in /Users/woojjam/anaconda3/lib/python3.11/site-packages (8.0.176)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (4.8.0.76)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: psutil in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from ultralytics) (8.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.2.2->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.2.2->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.2.2->ultralytics) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.2.2->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2022.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: filelock in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: six in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from cycler>=0.10->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/woojjam/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyYAML # ÌååÏù¥Ïç¨ÏóêÏÑú YAML ÌååÏùºÏùÑ ÏÇ¨Ïö©ÌïòÍ∏∞ ÏúÑÌï¥ÏÑú PyYAML ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['trash'],\n",
       " 'nc': 1,\n",
       " 'test': '/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/',\n",
       " 'train': '/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/train/images/',\n",
       " 'val': '/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/valid/images/'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "data = {\n",
    "    'train' :'/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/train/images/',\n",
    "    'val' :'/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/valid/images/',\n",
    "    'test' : '/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/',\n",
    "    'names' : ['trash'],\n",
    "    'nc':1 }\n",
    "\n",
    "with open('/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/TACO.yaml', 'w') as f:\n",
    "    yaml.dump(data,f)\n",
    "\n",
    "with open('/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/TACO.yaml','r') as f:\n",
    "    taco_yaml = yaml.safe_load(f)\n",
    "    display(taco_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.176 üöÄ Python-3.11.4 torch-2.0.1 CPU (Apple M1)\n",
      "Setup complete ‚úÖ (8 CPUs, 16.0 GB RAM, 131.5/228.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n-seg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 80\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "print(type(model.names), len(model.names))\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.180 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.176 üöÄ Python-3.11.4 torch-2.0.1 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/TACO.yaml, epochs=2, patience=10, batch=32, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train12\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3263811 parameters, 3263795 gradients\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/train/labels.cache... 3146 images, 23 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3146/3146 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/valid/labels.cache... 299 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 299/299 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/segment/train12/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train12\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/2         0G      1.302      2.383      2.005      1.134         69        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [11:29<00:00,  6.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:33<00:00,  6.66s/it]\n",
      "                   all        299       1014     0.0952       0.15     0.0707     0.0388      0.102      0.153     0.0683     0.0358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/2         0G      1.329      2.332      1.562      1.148         47        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [11:59<00:00,  7.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:32<00:00,  6.49s/it]\n",
      "                   all        299       1014      0.556      0.324      0.343      0.209      0.582      0.316      0.329      0.178\n",
      "\n",
      "2 epochs completed in 0.410 hours.\n",
      "Optimizer stripped from runs/segment/train12/weights/last.pt, 6.7MB\n",
      "Optimizer stripped from runs/segment/train12/weights/best.pt, 6.7MB\n",
      "\n",
      "Validating runs/segment/train12/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.176 üöÄ Python-3.11.4 torch-2.0.1 CPU (Apple M1)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258259 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:33<00:00,  6.60s/it]\n",
      "                   all        299       1014      0.532       0.34      0.343      0.209      0.584      0.316      0.329      0.178\n",
      "Speed: 0.4ms preprocess, 88.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train12\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.SegmentMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x16e22d650>\n",
       "fitness: 0.41592759245277544\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'metrics/precision(M)', 'metrics/recall(M)', 'metrics/mAP50(M)', 'metrics/mAP50-95(M)']\n",
       "maps: array([     0.3875])\n",
       "names: {0: 'trash'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.5321125605869939, 'metrics/recall(B)': 0.34023668639053256, 'metrics/mAP50(B)': 0.3426236095395709, 'metrics/mAP50-95(B)': 0.2091176847190081, 'metrics/precision(M)': 0.5837763577540972, 'metrics/recall(M)': 0.3155818540433925, 'metrics/mAP50(M)': 0.32915833684028434, 'metrics/mAP50-95(M)': 0.17838164618631397, 'fitness': 0.41592759245277544}\n",
       "save_dir: PosixPath('runs/segment/train12')\n",
       "seg: ultralytics.utils.metrics.Metric object\n",
       "speed: {'preprocess': 0.4235510044672019, 'inference': 88.30668615258259, 'loss': 2.2326823461015883e-05, 'postprocess': 1.1867209023057816}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(data='/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/TACO.yaml', epochs=2, patience=10, batch=32, imgsz=416)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 1\n",
      "{0: 'trash'}\n"
     ]
    }
   ],
   "source": [
    "print(type(model.names), len(model.names))\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000001_JPG.rf.1cebaa7292e525c3616c1e6626718cee.jpg: 416x416 4 trashs, 52.2ms\n",
      "image 2/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000002_jpg.rf.f0c70585c8465d2c8a31110463f678ce.jpg: 416x416 1 trash, 47.4ms\n",
      "image 3/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000004_jpg.rf.f220eaab0f36226385a34eb0708f9936.jpg: 416x416 3 trashs, 47.6ms\n",
      "image 4/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000005_jpg.rf.28c2d4c5813f54368ede1bfa04bc3ad1.jpg: 416x416 1 trash, 44.0ms\n",
      "image 5/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000006_JPG.rf.a75a06bbee739f71071fe6e17c41aebe.jpg: 416x416 1 trash, 47.5ms\n",
      "image 6/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000006_jpg.rf.65db7183891046d795545fe4380c669e.jpg: 416x416 2 trashs, 58.1ms\n",
      "image 7/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000007_jpg.rf.dd2e13df00283d2c2eae9ce1be62d699.jpg: 416x416 5 trashs, 51.8ms\n",
      "image 8/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000008_JPG.rf.a77058c3add4ea4c06fdde3412ac3bb8.jpg: 416x416 2 trashs, 47.4ms\n",
      "image 9/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000008_jpg.rf.22c2b4dc5775d9e77b17def192b06a0b.jpg: 416x416 (no detections), 51.4ms\n",
      "image 10/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000008_jpg.rf.aa0b1337eb8b1a929322da48911a82b6.jpg: 416x416 2 trashs, 50.3ms\n",
      "image 11/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000008_jpg.rf.b3199b37d1fa410300f28bf7f99ff45c.jpg: 416x416 1 trash, 56.2ms\n",
      "image 12/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000008_jpg.rf.f53f29094d3ea469578f64775912b2f2.jpg: 416x416 1 trash, 47.1ms\n",
      "image 13/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000009_jpg.rf.471c05a01ed517441e1f5f1d7a60c97f.jpg: 416x416 (no detections), 53.6ms\n",
      "image 14/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000010_JPG.rf.72c8f9daa24509b4434daf767558a9b3.jpg: 416x416 4 trashs, 51.7ms\n",
      "image 15/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000010_jpg.rf.5bc9e0eb8f2c5b0a6b7a091903d6cbf6.jpg: 416x416 7 trashs, 52.0ms\n",
      "image 16/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000010_jpg.rf.ed8a820c2c909ae6b1b064cec888bb50.jpg: 416x416 4 trashs, 52.1ms\n",
      "image 17/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000012_JPG.rf.1647e92cbed202caab553d851f870723.jpg: 416x416 1 trash, 47.7ms\n",
      "image 18/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000013_jpg.rf.901f0cf1e6645a364919d258ab5f33ca.jpg: 416x416 2 trashs, 49.9ms\n",
      "image 19/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000014_jpg.rf.59884975b116d751b7d07e2766c7b9f0.jpg: 416x416 4 trashs, 53.3ms\n",
      "image 20/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000015_jpg.rf.3e2a474c9588ee1edddb8237a7ea2737.jpg: 416x416 1 trash, 48.9ms\n",
      "image 21/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000015_jpg.rf.cfc3c88dd57be2e4de1682f17cacfd12.jpg: 416x416 4 trashs, 54.3ms\n",
      "image 22/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000016_JPG.rf.cf0ddb5692075ee87667d4d63093105c.jpg: 416x416 1 trash, 55.3ms\n",
      "image 23/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000016_jpg.rf.4b28c8d1a9cf138589839073f46a994d.jpg: 416x416 6 trashs, 53.3ms\n",
      "image 24/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000018_JPG.rf.132ece8a7ecac5c06006c0a095ca2582.jpg: 416x416 1 trash, 55.2ms\n",
      "image 25/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000019_JPG.rf.3258b1b6ecab3e36e6014ede30aa4169.jpg: 416x416 1 trash, 51.6ms\n",
      "image 26/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000020_JPG.rf.71b30e8b28518cfcfdd99e247a7a9ce7.jpg: 416x416 (no detections), 51.3ms\n",
      "image 27/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000020_jpg.rf.7ba985d97b0f31ca7c1f6fed29020c91.jpg: 416x416 1 trash, 53.7ms\n",
      "image 28/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000021_jpg.rf.4719fca029ba98baf3e2213a9ceb76ce.jpg: 416x416 1 trash, 51.2ms\n",
      "image 29/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000021_jpg.rf.e5a1cdd8ffa27cdba13ca1b559f92ebd.jpg: 416x416 1 trash, 64.7ms\n",
      "image 30/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000023_JPG.rf.a3f9316515561b1791d76c36efb0a0bb.jpg: 416x416 2 trashs, 59.6ms\n",
      "image 31/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000023_JPG.rf.d31dbd087328c3904b68dbecccc5c028.jpg: 416x416 1 trash, 58.0ms\n",
      "image 32/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000024_JPG.rf.1dd671bbf8939f11d43be6cbe6364be5.jpg: 416x416 7 trashs, 50.9ms\n",
      "image 33/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000025_jpg.rf.0da13b81ec0c5049f290464d450047ad.jpg: 416x416 2 trashs, 74.9ms\n",
      "image 34/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000025_jpg.rf.fa839df7d64298467bdcca0eabb1fbec.jpg: 416x416 4 trashs, 53.1ms\n",
      "image 35/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000026_jpg.rf.697322d4f370d27c156d635167c39d98.jpg: 416x416 4 trashs, 49.3ms\n",
      "image 36/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000026_jpg.rf.7963954dde2ad497b3ba1814f5c10913.jpg: 416x416 4 trashs, 69.4ms\n",
      "image 37/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000027_jpg.rf.8374965a40bb232c3375929a7dcf934a.jpg: 416x416 1 trash, 56.4ms\n",
      "image 38/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000028_jpg.rf.898d7f23f160ddc9cdac3c19a8d28d19.jpg: 416x416 3 trashs, 57.5ms\n",
      "image 39/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000029_jpg.rf.03b5b472eb6f070ca6f541c5e1988e9a.jpg: 416x416 1 trash, 56.2ms\n",
      "image 40/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000029_jpg.rf.0944b99b179ad865183e75029c5f3449.jpg: 416x416 (no detections), 49.2ms\n",
      "image 41/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000030_jpg.rf.3a75846cee62c437c624f3b9d5a4f4b7.jpg: 416x416 (no detections), 49.9ms\n",
      "image 42/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000031_jpg.rf.7cb86f7ed025fa45e49dc51bdc451031.jpg: 416x416 3 trashs, 51.5ms\n",
      "image 43/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000032_jpg.rf.4741b5b31e33bdd08fcb8aaeed05e55a.jpg: 416x416 2 trashs, 47.6ms\n",
      "image 44/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000032_jpg.rf.7f408daf965344f6660396a7249fdac7.jpg: 416x416 1 trash, 46.7ms\n",
      "image 45/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000032_jpg.rf.932170dfab96fd24e76bc8ccc10f4962.jpg: 416x416 (no detections), 48.2ms\n",
      "image 46/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000034_jpg.rf.bc61a35ad33dcacaa9c4c9a55d8245b2.jpg: 416x416 2 trashs, 50.8ms\n",
      "image 47/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000035_JPG.rf.2017d08e975e7fd491e2cfdef5aaba57.jpg: 416x416 2 trashs, 54.1ms\n",
      "image 48/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000035_JPG.rf.7c2015eaa20214cc541b0835e58a5c4a.jpg: 416x416 (no detections), 47.6ms\n",
      "image 49/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000035_JPG.rf.fe59673c2c23edf649c9334407b93990.jpg: 416x416 3 trashs, 52.4ms\n",
      "image 50/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000035_jpg.rf.468d938bb681216d1ba40fd52980eb1c.jpg: 416x416 3 trashs, 49.0ms\n",
      "image 51/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000035_jpg.rf.7dce3734442f29172c88369b59eecc98.jpg: 416x416 1 trash, 51.1ms\n",
      "image 52/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000035_jpg.rf.b0f2e5ced5c279a23b5b38c769375e18.jpg: 416x416 1 trash, 56.0ms\n",
      "image 53/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000037_jpg.rf.cf2a6ee5b9c78d9f1e802c032f012fa0.jpg: 416x416 1 trash, 54.0ms\n",
      "image 54/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000038_jpg.rf.68db38198d0b34ea257cbdd88ca689a9.jpg: 416x416 3 trashs, 48.8ms\n",
      "image 55/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000039_JPG.rf.f27d51db2a6deed69098bb6ca048a8bb.jpg: 416x416 1 trash, 50.3ms\n",
      "image 56/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000040_JPG.rf.e486cfc6a5a4f1bb7830754c3170cc34.jpg: 416x416 1 trash, 53.7ms\n",
      "image 57/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000041_JPG.rf.2d4973b7d94368a1be2b965d43fe7964.jpg: 416x416 (no detections), 51.5ms\n",
      "image 58/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000042_JPG.rf.63732c5791e92b7f42a2df3449f950a1.jpg: 416x416 2 trashs, 53.5ms\n",
      "image 59/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000043_JPG.rf.62dc8114b4ca0a64b81bfe1748b33126.jpg: 416x416 (no detections), 51.7ms\n",
      "image 60/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000043_jpg.rf.c8373c693e2582e581ce8b37906ac5c0.jpg: 416x416 (no detections), 51.3ms\n",
      "image 61/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000043_jpg.rf.cd1505a6ec3de6994dabc7e67fcde2ca.jpg: 416x416 (no detections), 51.5ms\n",
      "image 62/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000044_jpg.rf.1df49737726d75b8b1a16bdb81c7df7e.jpg: 416x416 (no detections), 50.1ms\n",
      "image 63/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000044_jpg.rf.f54c8c4c8cf9d987a38451d657201394.jpg: 416x416 1 trash, 55.9ms\n",
      "image 64/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000045_jpg.rf.3f341c65524e6a7998ab0ec832a88da7.jpg: 416x416 (no detections), 51.8ms\n",
      "image 65/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000048_JPG.rf.3f0e74eb291156a7decc415221539ccb.jpg: 416x416 8 trashs, 51.0ms\n",
      "image 66/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000048_jpg.rf.e60d9a4fb2291413fbfb09d6d8469a5f.jpg: 416x416 2 trashs, 50.7ms\n",
      "image 67/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000049_jpg.rf.3dafa35926a5236ccb3bfb50b0580bec.jpg: 416x416 2 trashs, 52.1ms\n",
      "image 68/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000049_jpg.rf.fcecf0afe84f57f6c31d3676d2e094f1.jpg: 416x416 3 trashs, 50.7ms\n",
      "image 69/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000050_JPG.rf.a9da853edb89821d81c22107667f0c5c.jpg: 416x416 1 trash, 50.9ms\n",
      "image 70/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000051_jpg.rf.02296bd519f51a571b5c151308fdb533.jpg: 416x416 1 trash, 54.4ms\n",
      "image 71/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000051_jpg.rf.902992fde0ac46790b0c34e0ddb12519.jpg: 416x416 1 trash, 59.5ms\n",
      "image 72/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000052_JPG.rf.78419e5978d1c3325c603c3d7048c3d8.jpg: 416x416 4 trashs, 59.2ms\n",
      "image 73/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000052_jpg.rf.86254fe9a48e1113cc49a48b80861beb.jpg: 416x416 4 trashs, 53.3ms\n",
      "image 74/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000052_jpg.rf.cc46d46b992fa4fc4edd619ef2c338d3.jpg: 416x416 9 trashs, 47.6ms\n",
      "image 75/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000052_jpg.rf.d8d459918abad812b302ba237f16f54e.jpg: 416x416 (no detections), 56.3ms\n",
      "image 76/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000053_jpg.rf.4bc6759aad89e84b13050cadfa935298.jpg: 416x416 7 trashs, 51.8ms\n",
      "image 77/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000054_jpg.rf.c77727a9cdb3f146d4b3b402a0fb07e2.jpg: 416x416 2 trashs, 72.3ms\n",
      "image 78/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000054_jpg.rf.f5853602ae12113e67a608efe01b0fd5.jpg: 416x416 1 trash, 51.3ms\n",
      "image 79/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000055_jpg.rf.4fc2ceed5f0807a5871e52ccf6351652.jpg: 416x416 (no detections), 52.5ms\n",
      "image 80/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000056_JPG.rf.49cd41eb4c688eee55ebb154dc7314bd.jpg: 416x416 5 trashs, 50.0ms\n",
      "image 81/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000059_JPG.rf.028aac050bf3ead32b958e4b87316685.jpg: 416x416 (no detections), 47.9ms\n",
      "image 82/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000060_JPG.rf.eb99016405c0166041663a06cc718fae.jpg: 416x416 2 trashs, 48.2ms\n",
      "image 83/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000061_JPG.rf.eb0796a0e439cc4b5d40b45d285b75c5.jpg: 416x416 1 trash, 49.2ms\n",
      "image 84/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000061_jpg.rf.0d77dd414bcad658e850be5782482059.jpg: 416x416 4 trashs, 55.9ms\n",
      "image 85/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000061_jpg.rf.7d6ea628bdcec8f3e586cdd79ba6c0fc.jpg: 416x416 1 trash, 46.3ms\n",
      "image 86/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000062_JPG.rf.304222dbb069670caf7e315e86379022.jpg: 416x416 (no detections), 46.8ms\n",
      "image 87/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000063_JPG.rf.624d8e347858f06cb3b827890fa9078c.jpg: 416x416 1 trash, 44.8ms\n",
      "image 88/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000063_jpg.rf.1e08dc417df232ce46747ea33fa24bf0.jpg: 416x416 1 trash, 42.8ms\n",
      "image 89/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000064_JPG.rf.9695789cbc6409a104c78f84fdbb38af.jpg: 416x416 (no detections), 45.2ms\n",
      "image 90/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000064_jpg.rf.6957f5b0a5cfc129d1cba0e9516c2580.jpg: 416x416 1 trash, 43.5ms\n",
      "image 91/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000065_JPG.rf.43098e580368726fa65651fe5dfe5891.jpg: 416x416 3 trashs, 41.6ms\n",
      "image 92/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000068_JPG.rf.389c5b6a7357928383d5e897dffe60b1.jpg: 416x416 3 trashs, 43.8ms\n",
      "image 93/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000068_jpg.rf.70ee48bd17fd687e94321f5953a98a81.jpg: 416x416 1 trash, 49.2ms\n",
      "image 94/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000068_jpg.rf.eb4d6e0bffb4621a479c67f32dc37cd3.jpg: 416x416 1 trash, 64.0ms\n",
      "image 95/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000069_JPG.rf.531900cae78728d31b35c7e7cc5ea002.jpg: 416x416 1 trash, 48.4ms\n",
      "image 96/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000070_JPG.rf.4d716bca141a38b15cfa2061d835ccce.jpg: 416x416 1 trash, 62.0ms\n",
      "image 97/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000071_JPG.rf.52875eb45322640761a93c091ae9e2f0.jpg: 416x416 2 trashs, 62.6ms\n",
      "image 98/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000071_JPG.rf.9049e6cc4e9a3bd60ede45e115a6a3a8.jpg: 416x416 1 trash, 46.5ms\n",
      "image 99/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000071_jpg.rf.612293c6aa1ed54261118006a0e7ce97.jpg: 416x416 1 trash, 48.6ms\n",
      "image 100/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000072_JPG.rf.2a0c2da392b97d53c7130bcb09321bca.jpg: 416x416 2 trashs, 48.7ms\n",
      "image 101/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000072_jpg.rf.c7e52d3c7d9af81057af7c4a51b2f073.jpg: 416x416 (no detections), 45.6ms\n",
      "image 102/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000073_JPG.rf.abf8486d86083697fed8435c91b5b160.jpg: 416x416 1 trash, 44.3ms\n",
      "image 103/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000074_JPG.rf.1394c939daf3a1345ce94470279bca71.jpg: 416x416 1 trash, 44.0ms\n",
      "image 104/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000074_jpg.rf.0aa8c88568ca60ae82d4e611f1db2cd0.jpg: 416x416 2 trashs, 52.7ms\n",
      "image 105/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000075_jpg.rf.69cbd9d7e624318f9f8a687d001fc7e2.jpg: 416x416 (no detections), 47.9ms\n",
      "image 106/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000075_jpg.rf.9ae739af5babaa9bb0c6d568cde46188.jpg: 416x416 1 trash, 55.1ms\n",
      "image 107/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000076_JPG.rf.0f6866174d7826dc2463fa0fb796623d.jpg: 416x416 2 trashs, 45.6ms\n",
      "image 108/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000076_jpg.rf.786b8ba153271d619e907af24bdd9c5b.jpg: 416x416 1 trash, 46.8ms\n",
      "image 109/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000076_jpg.rf.f7c13be4fef8c40ce4023446dcead507.jpg: 416x416 4 trashs, 45.9ms\n",
      "image 110/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000078_jpg.rf.8a5b754f419501304b90746988441b26.jpg: 416x416 3 trashs, 45.1ms\n",
      "image 111/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000078_jpg.rf.bb8e2bcda38def48b790caacb311ab52.jpg: 416x416 2 trashs, 44.0ms\n",
      "image 112/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000079_JPG.rf.3a6209547c1141ffa41b1090a4e1e946.jpg: 416x416 1 trash, 40.9ms\n",
      "image 113/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000079_JPG.rf.97573b5bbf495aab757757cacac1d966.jpg: 416x416 3 trashs, 45.6ms\n",
      "image 114/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000079_jpg.rf.28570dfb665c47466eecf93603b7304e.jpg: 416x416 1 trash, 46.4ms\n",
      "image 115/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000080_jpg.rf.2afc1e2e6fba46387ec4fc1e17651a85.jpg: 416x416 5 trashs, 46.0ms\n",
      "image 116/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000080_jpg.rf.37ab1fb0e2496050a812f9e22b84c77f.jpg: 416x416 (no detections), 45.8ms\n",
      "image 117/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000081_JPG.rf.2319b8759407604e929c89f9b6138466.jpg: 416x416 (no detections), 44.7ms\n",
      "image 118/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000083_JPG.rf.b8531e469adf93cb7cdeacff167209bd.jpg: 416x416 2 trashs, 44.6ms\n",
      "image 119/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000083_jpg.rf.3e6b61cb83e9e6dbf1404258be3fb74c.jpg: 416x416 1 trash, 46.6ms\n",
      "image 120/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000083_jpg.rf.6292450946e99afb9725b539086dc19f.jpg: 416x416 2 trashs, 43.3ms\n",
      "image 121/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000084_JPG.rf.b51214803423b9b953e50ed9fe3f68f5.jpg: 416x416 1 trash, 41.4ms\n",
      "image 122/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000084_jpg.rf.b32e8bd754a9e927a4e7e64020e95227.jpg: 416x416 1 trash, 45.0ms\n",
      "image 123/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000085_jpg.rf.75884efc13a2bb924dab5e41f8c7b5bc.jpg: 416x416 4 trashs, 45.1ms\n",
      "image 124/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000086_jpg.rf.0e1718f05e70c70e0852bfaa452be4b9.jpg: 416x416 2 trashs, 70.8ms\n",
      "image 125/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000087_jpg.rf.c684755954097a754838ba72064bac68.jpg: 416x416 3 trashs, 41.9ms\n",
      "image 126/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000088_JPG.rf.a707859aadb8cd85c9326c4d5c39e2ea.jpg: 416x416 (no detections), 43.1ms\n",
      "image 127/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000089_jpg.rf.51087b4f6691213a3cd86a83713ceee7.jpg: 416x416 (no detections), 48.5ms\n",
      "image 128/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000090_JPG.rf.622a716ad6aa77cbdbdb55248f5977d3.jpg: 416x416 1 trash, 43.2ms\n",
      "image 129/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000090_JPG.rf.ff06da68f5ad998d607b1919d553c86f.jpg: 416x416 1 trash, 44.1ms\n",
      "image 130/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000090_jpg.rf.c0e88e1badfb36138b3d3eace9b17c62.jpg: 416x416 2 trashs, 44.7ms\n",
      "image 131/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000091_JPG.rf.e61c43926ec03e21ce4fa28d5ed032bf.jpg: 416x416 1 trash, 44.0ms\n",
      "image 132/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000094_JPG.rf.e9a71419b4eabd6e46481dc355cb85c1.jpg: 416x416 6 trashs, 43.1ms\n",
      "image 133/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000097_jpg.rf.6316afdad8a31ff1837489631896c4e6.jpg: 416x416 3 trashs, 41.4ms\n",
      "image 134/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000098_JPG.rf.175d52b02ea9854703ea454780ad9fa7.jpg: 416x416 2 trashs, 43.0ms\n",
      "image 135/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000102_JPG.rf.6c03a759782f70dcf0cd9e1645f34a33.jpg: 416x416 2 trashs, 42.8ms\n",
      "image 136/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000114_JPG.rf.3dd3877b41e428ab885ababd71726a42.jpg: 416x416 1 trash, 43.7ms\n",
      "image 137/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000115_JPG.rf.9a0f1cf5a04715c60637fd7039006e62.jpg: 416x416 (no detections), 46.6ms\n",
      "image 138/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000118_JPG.rf.8ee6123eb01487a6894abd3302cc3d51.jpg: 416x416 1 trash, 41.4ms\n",
      "image 139/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000119_JPG.rf.06c68e56c48f0763642aff1973d8e228.jpg: 416x416 1 trash, 41.9ms\n",
      "image 140/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000119_JPG.rf.6e478ee5d62aa8c57514dd0e6ddd8fbc.jpg: 416x416 1 trash, 40.8ms\n",
      "image 141/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/000142_JPG.rf.846277276a1d88a8cbb26883fc1ea3cd.jpg: 416x416 1 trash, 43.4ms\n",
      "image 142/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_4857_JPG.rf.fbcca95a2fa009e83eaba772703623c8.jpg: 416x416 2 trashs, 41.5ms\n",
      "image 143/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_4859_JPG.rf.9fc845b63829788ce373392eefad852b.jpg: 416x416 2 trashs, 43.4ms\n",
      "image 144/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_4860_JPG.rf.5581a44ea64978ea0fccb44ffb977916.jpg: 416x416 4 trashs, 39.2ms\n",
      "image 145/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_4878_JPG.rf.594e616658fe1f225d57e99557bfaed1.jpg: 416x416 2 trashs, 42.2ms\n",
      "image 146/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_4901_JPG.rf.edc396f54f8dba16d9b830611208ef1f.jpg: 416x416 (no detections), 43.2ms\n",
      "image 147/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_4926_JPG.rf.171eb4ce76ce6343afa39222f3e40554.jpg: 416x416 4 trashs, 45.2ms\n",
      "image 148/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_4978_JPG.rf.45544bad0d670049ec20475f67988aea.jpg: 416x416 7 trashs, 44.7ms\n",
      "image 149/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_5042_JPG.rf.c3fe59135bac46db84ae905242f3e52f.jpg: 416x416 2 trashs, 43.7ms\n",
      "image 150/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_5055_JPG.rf.d1799fed887494801b1df732128592d5.jpg: 416x416 (no detections), 44.6ms\n",
      "image 151/151 /Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/IMG_5060_JPG.rf.c0b4ca4b5191baf018f3df11b0e4441a.jpg: 416x416 1 trash, 43.5ms\n",
      "Speed: 0.9ms preprocess, 49.7ms inference, 0.8ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(source='/Users/woojjam/Desktop/study/machine-learning/yolo/yolov8/custom_data_instance_segmetation/test/images/', save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
